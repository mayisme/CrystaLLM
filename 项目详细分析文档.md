# CrystaLLM 项目详细分析文档

## 目录

1. [项目概述](#1-项目概述)
2. [核心技术与创新](#2-核心技术与创新)
3. [项目架构深度解析](#3-项目架构深度解析)
4. [应用场景与用途](#4-应用场景与用途)
5. [完整工作流程](#5-完整工作流程)
6. [技术实现细节](#6-技术实现细节)
7. [模型训练与优化](#7-模型训练与优化)
8. [高级功能详解](#8-高级功能详解)
9. [实际应用案例](#9-实际应用案例)
10. [性能评估与基准测试](#10-性能评估与基准测试)
11. [扩展与定制](#11-扩展与定制)
12. [技术优势与局限](#12-技术优势与局限)

---

## 1. 项目概述

### 1.1 项目简介

**CrystaLLM** (Crystal Large Language Model) 是一个革命性的晶体结构生成系统，将自然语言处理中的大型语言模型技术应用于材料科学领域。该项目由 Nature Communications 期刊发表（2024年），代表了人工智能在材料设计领域的重大突破。

### 1.2 核心特性

- **基于 GPT-2 架构**：采用经过验证的 Transformer 架构进行晶体结构序列生成
- **大规模训练数据**：基于 228 万个晶体结构（来自 Materials Project、OQMD 和 NOMAD 数据库）
- **条件生成能力**：支持根据化学组成和空间群生成特定晶体结构
- **高准确率**：生成结构的有效性达到 94%，空间群一致性达到 98.9%
- **多样化应用**：支持钙钛矿、碳材料等特定材料体系的生成

### 1.3 技术创新点

1. **首次将 LLM 技术应用于晶体学**：将 CIF 文件视为特殊的"语言"，使用 GPT 模型学习其语法和语义
2. **领域特定分词器**：设计专门针对 CIF 格式的 tokenizer，包含原子、空间群、关键词等特殊 token
3. **MCTS 增强生成**：结合蒙特卡洛树搜索，显著提高生成结构的稳定性和合理性
4. **自动验证系统**：内置多维度结构验证机制，确保生成结构的物理合理性

### 1.4 应用价值

- **加速材料发现**：快速生成候选材料结构，减少传统计算和实验成本
- **探索未知材料**：发现数据库中不存在但物理上可行的新结构
- **结构预测**：根据化学组成预测可能的晶体结构
- **材料设计辅助**：为特定应用（如太阳能电池、催化剂）设计材料

---

## 2. 核心技术与创新

### 2.1 语言模型与晶体学的结合

#### 2.1.1 问题重构

传统的晶体结构生成方法依赖于：
- **物理模拟**：从头算方法、密度泛函理论（DFT）
- **进化算法**：遗传算法、粒子群优化
- **基于规则**：晶体学对称性规则、空间群约束

CrystaLLM 将这个问题重新表述为：
```
晶体结构生成 → 序列生成问题
CIF 文件 → 特殊语言的文本
```

#### 2.1.2 技术类比

| 自然语言处理 | CrystaLLM |
|------------|-----------|
| 词汇表 | 原子符号、数字、关键词、空间群 |
| 语法规则 | CIF 格式规范、晶体学约束 |
| 语义 | 物理合理性、化学键合规则 |
| 文本生成 | 晶体结构生成 |

### 2.2 CIF 格式与 Token 化

#### 2.2.1 CIF 文件结构

CIF（Crystallographic Information File）包含：
```cif
data_CaTiO3                          # 数据块标识
_atom_type_symbol                    # 原子类型
_atom_type_electronegativity         # 电负性
_atom_type_radius                    # 原子半径
_symmetry_space_group_name_H-M Pm-3m # 空间群
_cell_length_a 3.8950                # 晶格参数
_cell_angle_alpha 90.0000            # 晶胞角度
loop_                                # 原子坐标循环
_atom_site_label
_atom_site_fract_x
...
```

#### 2.2.2 Token 设计

CrystaLLM 的分词器包含 **371 个 token**：
- **原子符号**：88 个元素（Si, C, O, Fe, ...）
- **数字**：0-9（10 个）
- **CIF 关键词**：25 个（如 `_cell_length_a`, `loop_`, `data_`）
- **空间群**：230 个国际符号（如 `Pm-3m`, `P63/mmc`）
- **符号**：13 个（如 `x`, `y`, `z`, `.`, `+`, `-`, `,`, 空格, 换行）
- **特殊 token**：`<unk>` 未知 token

特殊处理：
```python
# 'Pm' 空间群和 'Pm' 原子（Promethium）消歧
'Pm' (spacegroup) → 'Pm_sg'
'P1' (spacegroup) → 'P1_sg'
```

### 2.3 模型架构

#### 2.3.1 GPT-2 基础架构

```
输入序列 (Token IDs)
    ↓
Token Embedding (词嵌入)
    ↓
Position Embedding (位置编码)
    ↓
Transformer Blocks × N
│ ├─ Multi-Head Self-Attention
│ ├─ Layer Normalization
│ ├─ Feed-Forward Network
│ └─ Residual Connections
    ↓
Output Head (预测下一个 token)
    ↓
生成的 CIF 序列
```

#### 2.3.2 模型配置

**小型模型** (285 MB):
- 层数：12
- 注意力头：12
- 嵌入维度：768
- 参数量：约 1.24 亿

**大型模型** (2.2 GB):
- 层数：24
- 注意力头：16
- 嵌入维度：1024
- 参数量：约 3.54 亿

### 2.4 MCTS 增强生成

#### 2.4.1 标准采样的局限

随机采样（Temperature Sampling + Top-K）的问题：
- 可能生成物理上不合理的结构
- 局部最优：单次采样可能陷入低质量区域
- 缺乏全局优化

#### 2.4.2 MCTS 解决方案

蒙特卡洛树搜索（Monte Carlo Tree Search）：
```
初始提示
    ↓
┌─────────────────┐
│  Selection      │ 选择最有前景的分支
│  (PUCT/UCT)     │
└────────┬────────┘
    ↓
┌─────────────────┐
│  Expansion      │ 扩展新节点
│                 │
└────────┬────────┘
    ↓
┌─────────────────┐
│  Simulation     │ 完成 CIF 生成
│  (Rollout)      │
└────────┬────────┘
    ↓
┌─────────────────┐
│  Backpropagation│ 更新节点价值
│  (Reward)       │
└─────────────────┘
```

**奖励函数**：
- 结构有效性检查
- 键长合理性评分
- 外部评分器（如 ALIGNN 能量预测）

---

## 3. 项目架构深度解析

### 3.1 目录结构

```
CrystaLLM/
├── crystallm/              # 核心 Python 包
│   ├── __init__.py         # 包初始化，导出主要 API
│   ├── _tokenizer.py       # CIF 分词器
│   ├── _model.py           # GPT 模型定义
│   ├── _mcts.py            # MCTS 采样器
│   ├── _metrics.py         # 结构验证指标
│   ├── _utils.py           # CIF 处理工具
│   ├── _scorer.py          # 外部评分接口
│   ├── _configuration.py   # 配置解析
│   └── spacegroups.txt     # 230 个空间群列表
├── bin/                    # CLI 脚本
│   ├── download.py         # 下载数据和模型
│   ├── deduplicate.py      # 数据去重
│   ├── preprocess.py       # CIF 预处理
│   ├── tokenize_cifs.py    # Token 化
│   ├── split.py            # 数据集划分
│   ├── train.py            # 模型训练
│   ├── sample.py           # 随机采样
│   ├── mcts.py             # MCTS 生成
│   ├── postprocess.py      # 后处理
│   ├── evaluate_cifs.py    # 结构评估
│   ├── make_prompt_file.py # 生成提示
│   └── ...
├── config/                 # 模型配置文件
│   ├── crystallm_v1_small.yaml
│   ├── crystallm_perov_5_small.yaml
│   └── ...
├── examples/               # 示例脚本
│   ├── generate_perovskites.py  # 批量生成钙钛矿
│   ├── analyze_perovskites.py   # 结构分析
│   └── quickstart.sh            # 快速开始脚本
├── tests/                  # 单元测试
├── resources/              # 资源文件
└── README.md               # 主文档
```

### 3.2 核心模块详解

#### 3.2.1 `crystallm._tokenizer.py` - 分词器

**主要类**：`CIFTokenizer`

**功能**：
1. **Token 定义**：管理 371 个 token 的词汇表
2. **编码**：CIF 文本 → Token ID 序列
3. **解码**：Token ID 序列 → CIF 文本
4. **预处理**：空间群消歧、空格标准化

**关键方法**：
```python
tokenizer = CIFTokenizer()

# 编码
tokens = tokenizer.tokenize_cif(cif_string)
token_ids = tokenizer.encode(tokens)

# 解码
cif_string = tokenizer.decode(token_ids)

# 词汇表
token_to_id = tokenizer.token_to_id
id_to_token = tokenizer.id_to_token
```

#### 3.2.2 `crystallm._model.py` - GPT 模型

**主要类**：
- `GPTConfig`：模型配置数据类
- `GPT`：主模型类

**核心组件**：
```python
class GPT(nn.Module):
    def __init__(self, config):
        self.transformer = nn.ModuleDict({
            'wte': nn.Embedding(config.vocab_size, config.n_embd),  # Token 嵌入
            'wpe': nn.Embedding(config.block_size, config.n_embd),  # 位置嵌入
            'drop': nn.Dropout(config.dropout),
            'h': nn.ModuleList([Block(config) for _ in range(config.n_layer)]),  # Transformer 层
            'ln_f': LayerNorm(config.n_embd, bias=config.bias),
        })
        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)
```

**生成方法**：
```python
@torch.no_grad()
def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):
    # 自回归生成
    for _ in range(max_new_tokens):
        logits, _ = self(idx_cond)
        logits = logits[:, -1, :] / temperature
        if top_k is not None:
            # Top-K 采样
        probs = F.softmax(logits, dim=-1)
        idx_next = torch.multinomial(probs, num_samples=1)
        idx = torch.cat((idx, idx_next), dim=1)
```

#### 3.2.3 `crystallm._mcts.py` - MCTS 采样器

**主要类**：
- `MCTSSampler`：MCTS 主控制器
- `MCTSEvaluator`：结构评估器
- `PUCTSelector`：PUCT 选择策略
- `UCTSelector`：UCT 选择策略
- `GreedySelector`：贪婪选择策略
- `ContextSensitiveTreeBuilder`：上下文感知树构建器

**工作流程**：
```python
sampler = MCTSSampler(
    model=model,
    tokenizer=tokenizer,
    evaluator=evaluator,
    selector=selector,
    tree_builder=tree_builder,
    tree_width=10,
    max_depth=1000,
    num_simulations=200
)

# 执行 MCTS 搜索
cif_string = sampler.sample(prompt)
```

**评估指标**：
```python
class MCTSEvaluator:
    def evaluate(self, cif_str):
        # 1. 公式一致性检查
        # 2. 原子位点重数检查
        # 3. 键长合理性评分
        # 4. 空间群一致性检查
        # 5. 外部评分器（可选）
        return reward, is_valid
```

#### 3.2.4 `crystallm._metrics.py` - 验证指标

**主要函数**：

1. **键长合理性**：
```python
def bond_length_reasonableness_score(cif_str, tolerance=0.32):
    # 检查键长是否在预期范围内（±32%）
    # 考虑共价/离子键类型
    # 特殊处理氢键
    return score  # 0.0 - 1.0
```

2. **空间群一致性**：
```python
def is_space_group_consistent(cif_str):
    # 使用 pymatgen 的 SpacegroupAnalyzer
    # 比较声明的空间群与检测到的空间群
    return True/False
```

3. **公式一致性**：
```python
def is_formula_consistent(cif_str):
    # 检查 data_ 行、_chemical_formula_sum 和 _chemical_formula_structural 是否一致
    return True/False
```

4. **原子位点重数一致性**：
```python
def is_atom_site_multiplicity_consistent(cif_str):
    # 验证原子位点对称重数与实际原子数是否匹配
    return True/False
```

5. **综合有效性**：
```python
def is_valid(cif_str, bond_length_acceptability_cutoff=1.0):
    # 综合以上所有检查
    return True/False
```

#### 3.2.5 `crystallm._utils.py` - 工具函数

**CIF 处理工具**：
```python
# 提取信息
extract_data_formula(cif_str)           # 提取化学式
extract_space_group_symbol(cif_str)     # 提取空间群
extract_volume(cif_str)                 # 提取晶胞体积
extract_numeric_property(cif_str, key)  # 提取数值属性

# 修改 CIF
add_atomic_props_block(cif_str)         # 添加原子属性块
remove_atom_props_block(cif_str)        # 移除原子属性块
replace_symmetry_operators(cif_str, sg) # 替换对称操作
round_numbers(cif_str, decimals)        # 数字舍入
semisymmetrize_cif(cif_str)             # 半对称化

# 计算
get_unit_cell_volume(a,b,c,α,β,γ)       # 计算晶胞体积

# 嵌入
embeddings_from_csv(csv_file)           # 从 CSV 加载嵌入
```

### 3.3 CLI 脚本详解

#### 数据准备流程

```bash
# 1. 下载原始数据
python bin/download.py cifs_v1_orig.tar.gz

# 2. 转换格式
python bin/tar_to_pickle.py cifs_v1_orig.tar.gz cifs_v1_orig.pkl.gz

# 3. 去重
python bin/deduplicate.py cifs_v1_orig.pkl.gz --out cifs_v1_dedup.pkl.gz

# 4. 预处理
python bin/preprocess.py cifs_v1_dedup.pkl.gz --out cifs_v1_prep.pkl.gz

# 5. 数据集划分
python bin/split.py cifs_v1_prep.pkl.gz \
    --train_out cifs_v1_train.pkl.gz \
    --val_out cifs_v1_val.pkl.gz \
    --test_out cifs_v1_test.pkl.gz

# 6. Token 化
python bin/tokenize_cifs.py \
    --train_fname cifs_v1_train.pkl.gz \
    --val_fname cifs_v1_val.pkl.gz \
    --out_dir tokens_v1_train_val/

# 7. 识别起始索引
python bin/identify_starts.py \
    --dataset_fname tokens_v1_train_val.tar.gz \
    --out_fname starts_v1_train.pkl
```

#### 训练流程

```bash
python bin/train.py \
    --config=config/crystallm_v1_small.yaml \
    dataset=tokens_v1_train_val \
    out_dir=out/my_model \
    max_iters=600000 \
    learning_rate=6e-4 \
    batch_size=64 \
    device=cuda
```

#### 生成流程

```bash
# 1. 创建提示
python bin/make_prompt_file.py Na2Cl2 prompt.txt --spacegroup Pm-3m

# 2. 随机采样
python bin/sample.py \
    out_dir=out/my_model \
    start=FILE:prompt.txt \
    num_samples=10 \
    temperature=0.8 \
    top_k=10 \
    target=file

# 3. 后处理
python bin/postprocess.py raw_cifs/ processed_cifs/

# 或使用 MCTS
python bin/mcts.py \
    out_dir=out/my_model \
    start=FILE:prompt.txt \
    tree_width=10 \
    num_simulations=200 \
    scorer=random
```

---

## 4. 应用场景与用途

### 4.1 材料发现与设计

#### 4.1.1 新材料探索

**应用**：生成数据库中不存在的候选材料

**工作流程**：
1. 确定目标化学组成（如 Li-Co-O 体系）
2. 使用 CrystaLLM 生成多种可能的结构
3. 使用 DFT 计算验证稳定性和性能
4. 筛选出最有前景的候选材料

**实际案例**：
```bash
# 生成锂钴氧化物电池材料
python bin/generate_cifs.py \
    --model crystallm_v1_small \
    --prompts "Li2CoO3,LiCoO2,Li3Co2O5" \
    --num-gens 50 \
    --output battery_materials/
```

#### 4.1.2 钙钛矿太阳能材料

**应用**：设计高效太阳能电池材料

**特点**：
- ABX₃ 结构（A: 大阳离子，B: 小阳离子，X: 阴离子）
- 需要合适的带隙（1.1-1.6 eV）
- 结构稳定性至关重要

**实践**：
```bash
# 使用钙钛矿专用模型
python examples/generate_perovskites.py \
    --model crystallm_perov_5_small \
    --compositions "CsPbI3:Pm-3m,CsPbBr3:Pm-3m,CsSnI3:Pnma" \
    --num-samples 50 \
    --temperature 0.65

# 分析和筛选
python examples/analyze_perovskites.py \
    --input perovskites/ \
    --output analysis/ \
    --min-quality 80
```

**评估指标**：
- Goldschmidt 容忍因子：0.8-1.0
- 键长合理性：> 0.95
- 空间群一致性：必须满足

#### 4.1.3 催化剂设计

**应用**：设计高活性催化剂材料

**示例**：过渡金属氧化物
```bash
# 生成不同空间群的 TiO2
python bin/make_prompts.py \
    --compositions "TiO2" \
    --spacegroups "P42/mnm,I41/amd,Pbca" \
    --output prompts/

python bin/generate_cifs.py \
    --model crystallm_v1_small \
    --prompts prompts/ \
    --num-gens 20
```

#### 4.1.4 能量存储材料

**应用**：电池电极、超级电容器材料

**目标体系**：
- 锂离子电池：Li-M-O（M = Co, Ni, Mn）
- 钠离子电池：Na-M-O 体系
- 固态电解质：Li-La-Zr-O

### 4.2 结构预测

#### 4.2.1 实验结构预测

**场景**：已知化学组成，预测可能的晶体结构

**优势**：
- 比传统结构预测（如进化算法）快数百倍
- 可以生成多个候选结构
- 考虑了晶体学对称性

**对比**：
| 方法 | 时间 | 候选数 | 准确率 |
|-----|------|--------|--------|
| DFT + 进化算法 | 数天 | 10-20 | 高 |
| **CrystaLLM** | **分钟** | **100+** | **中-高** |
| 机器学习（其他）| 小时 | 50 | 中 |

#### 4.2.2 多态性研究

**应用**：研究同一化学组成的不同晶型

```bash
# 生成 CaCO3 的不同多态性
python bin/sample.py \
    out_dir=crystallm_v1_small \
    start=$'data_CaCO3\n' \
    num_samples=100 \
    temperature=1.0  # 较高温度增加多样性
```

### 4.3 教育与研究

#### 4.3.1 晶体学教学

**用途**：
- 演示晶体结构多样性
- 理解空间群对称性
- 学习 CIF 格式

#### 4.3.2 研究工具

**应用**：
- 生成训练数据（为其他 ML 模型）
- 结构完成（填补缺失的 CIF 信息）
- 结构优化起点

### 4.4 高通量筛选

#### 4.4.1 虚拟筛选流程

```python
# 大规模生成和筛选
compositions = ["CaTiO3", "SrTiO3", "BaTiO3", ...]  # 数百种组成

for comp in compositions:
    # 生成
    generate_structures(comp, num_samples=50)
    
    # 快速筛选
    valid_structures = filter_by_validity()
    
    # 初步 ML 筛选（如能量预测）
    promising = filter_by_ml_score(valid_structures)
    
    # DFT 精确计算
    final_candidates = dft_calculation(promising)
```

#### 4.4.2 性能优势

- **生成速度**：GPU 上每秒生成数十个结构
- **筛选效率**：内置验证快速排除无效结构
- **可扩展性**：易于并行化

---

## 5. 完整工作流程

### 5.1 从零开始：完整教程

#### 5.1.1 环境配置

```bash
# 1. 创建虚拟环境
python -m venv crystallm_env
source crystallm_env/bin/activate  # Linux/Mac
# crystallm_env\Scripts\activate  # Windows

# 2. 克隆项目
git clone https://github.com/lantunes/CrystaLLM.git
cd CrystaLLM

# 3. 安装依赖
pip install -r requirements.txt
pip install torch==2.0.1

# 4. 安装 crystallm 包
pip install -e .
```

#### 5.1.2 使用预训练模型（推荐）

```bash
# 1. 下载模型
python bin/download.py crystallm_v1_small.tar.gz

# 2. 解压
tar xvf crystallm_v1_small.tar.gz
# 得到 crystallm_v1_small/ 目录，包含 ckpt.pt

# 3. 生成结构
python bin/make_prompt_file.py "CaTiO3" prompt_catio3.txt --spacegroup "Pm-3m"

python bin/sample.py \
    out_dir=crystallm_v1_small \
    start=FILE:prompt_catio3.txt \
    num_samples=10 \
    temperature=0.75 \
    top_k=10 \
    target=file \
    device=cuda

# 4. 后处理
mkdir processed
python bin/postprocess.py . processed/

# 5. 评估
python bin/evaluate_cifs.py processed/ -o evaluation_results.csv
```

### 5.2 训练自己的模型

#### 5.2.1 准备自定义数据集

**场景**：训练专注于特定材料体系的模型

```bash
# 1. 准备 CIF 文件
# 将 CIF 文件放入 my_cifs/ 目录

# 2. 预处理
python bin/prepare_custom.py my_cifs/ my_dataset.tar.gz
python bin/tar_to_pickle.py my_dataset.tar.gz my_dataset.pkl.gz

# 3. 预处理 CIF
python bin/preprocess.py my_dataset.pkl.gz --out my_dataset_prep.pkl.gz

# 4. 划分数据集
python bin/split.py my_dataset_prep.pkl.gz \
    --train_out my_train.pkl.gz \
    --val_out my_val.pkl.gz \
    --test_out my_test.pkl.gz \
    --validation_size 0.10 \
    --test_size 0.10

# 5. Token 化
python bin/tokenize_cifs.py \
    --train_fname my_train.pkl.gz \
    --val_fname my_val.pkl.gz \
    --out_dir my_tokens/ \
    --workers 4

# 6. 识别起始索引（可选，但推荐）
python bin/identify_starts.py \
    --dataset_fname my_tokens/train.bin \
    --out_fname my_tokens/starts.pkl
```

#### 5.2.2 配置训练参数

创建 `my_config.yaml`：
```yaml
# 数据
dataset: "my_tokens"

# 模型架构
n_layer: 12
n_head: 12
n_embd: 768
block_size: 2048
dropout: 0.0
bias: False

# 优化器
learning_rate: 6e-4
max_iters: 100000
weight_decay: 1e-1
beta1: 0.9
beta2: 0.95
grad_clip: 1.0

# 学习率调度
decay_lr: True
warmup_iters: 2000
lr_decay_iters: 100000
min_lr: 6e-5

# 训练设置
batch_size: 32
gradient_accumulation_steps: 2
eval_interval: 500
eval_iters_train: 100
eval_iters_val: 100
always_save_checkpoint: True

# 系统
device: "cuda"
dtype: "bfloat16"
compile: True
validate: True

# 输出
out_dir: "out/my_custom_model"
```

#### 5.2.3 开始训练

```bash
# 单 GPU 训练
python bin/train.py --config=my_config.yaml

# 多 GPU 训练（需要 torchrun）
torchrun --nproc_per_node=4 bin/train.py --config=my_config.yaml

# 从检查点恢复
python bin/train.py --config=my_config.yaml init_from=resume
```

**监控训练**：
```python
# 训练过程会输出：
# iter 1000: loss 2.5234, time 1234.56ms, mfu 12.34%
# val loss 2.6789

# 检查点保存在 out_dir/ckpt.pt
```

### 5.3 高级生成技术

#### 5.3.1 使用 MCTS 生成高质量结构

```bash
# 1. 设置外部评分器（可选但推荐）
# 例如使用 ALIGNN 能量预测
python resources/alignn_zmq_example.py &  # 后台运行

# 2. 使用 MCTS 生成
python bin/mcts.py \
    out_dir=crystallm_v1_small \
    start=FILE:prompt_catio3.txt \
    tree_width=10 \
    max_depth=2000 \
    selector=puct \
    c=1.0 \
    num_simulations=500 \
    reward_k=-2.0 \
    scorer=zmq \
    scorer_host=localhost \
    scorer_port=5555 \
    mcts_out_dir=mcts_output \
    device=cuda
```

**MCTS 参数调优**：
- `tree_width`：每个节点的子节点数（5-15）
- `num_simulations`：模拟次数（200-1000）
- `c`：探索参数（0.5-5.0）
- `reward_k`：奖励灵敏度（-5.0 到 5.0）

#### 5.3.2 批量生成

```python
# batch_generate.py
import subprocess
from pathlib import Path

compositions = [
    ("CaTiO3", "Pm-3m"),
    ("SrTiO3", "Pm-3m"),
    ("BaTiO3", "P4mm"),
    # ... 更多组成
]

for comp, sg in compositions:
    # 创建提示
    prompt_file = f"prompts/{comp}_{sg}.txt"
    subprocess.run([
        "python", "bin/make_prompt_file.py",
        comp, prompt_file, "--spacegroup", sg
    ])
    
    # 生成
    output_dir = f"generated/{comp}_{sg}"
    Path(output_dir).mkdir(parents=True, exist_ok=True)
    
    subprocess.run([
        "python", "bin/sample.py",
        f"out_dir=crystallm_v1_small",
        f"start=FILE:{prompt_file}",
        "num_samples=20",
        "temperature=0.75",
        "top_k=10",
        "target=file"
    ], cwd=output_dir)
    
    # 后处理
    subprocess.run([
        "python", "bin/postprocess.py",
        ".", "processed/"
    ], cwd=output_dir)
```

### 5.4 结果分析与可视化

#### 5.4.1 评估生成质量

```bash
python bin/evaluate_cifs.py generated/ -o evaluation.csv
```

输出：
```
space group consistent: 9823/10000 (0.982)
atom site multiplicity consistent: 9910/10000 (0.991)
avg. bond length reasonableness score: 0.9856 ± 0.0712
bond lengths reasonable: 9564/10000 (0.956)
num valid: 9421/10000 (0.942)
```

#### 5.4.2 结构可视化

```python
# visualize.py
from pymatgen.io.cif import CifParser
from pymatgen.vis.structure_vtk import StructureVis

# 读取 CIF
parser = CifParser("processed/sample_1.cif")
structure = parser.get_structures()[0]

# 可视化
vis = StructureVis()
vis.set_structure(structure)
vis.show()

# 或导出为其他格式
from pymatgen.io.vasp import Poscar
poscar = Poscar(structure)
poscar.write_file("sample_1.POSCAR")
```

#### 5.4.3 统计分析

```python
# analysis.py
import pandas as pd
import matplotlib.pyplot as plt

# 读取评估结果
df = pd.read_csv("evaluation.csv")

# 统计有效结构比例
valid_rate = df["is_valid"].mean()
print(f"Valid rate: {valid_rate:.2%}")

# 键长分数分布
plt.figure(figsize=(10, 6))
plt.hist(df["bond_length_score"], bins=50)
plt.xlabel("Bond Length Reasonableness Score")
plt.ylabel("Count")
plt.title("Distribution of Bond Length Scores")
plt.savefig("bond_length_distribution.png")

# 按空间群统计
sg_stats = df.groupby("space_group").agg({
    "is_valid": ["count", "mean"],
    "bond_length_score": "mean"
})
print(sg_stats)
```

---

## 6. 技术实现细节

### 6.1 数据预处理

#### 6.1.1 去重策略

**问题**：原始数据集包含重复结构

**解决方案**：
```python
# bin/deduplicate.py
# 去重键：(化学组成, 空间群)
# 选择标准：最小单位体积

def deduplicate_cifs(cif_list):
    key_to_cif = {}
    for cif_id, cif_str in cif_list:
        formula = extract_formula(cif_str)
        spacegroup = extract_spacegroup(cif_str)
        volume_per_formula = calculate_volume_per_formula(cif_str)
        
        key = (formula, spacegroup)
        if key not in key_to_cif:
            key_to_cif[key] = (cif_id, cif_str, volume_per_formula)
        else:
            existing_volume = key_to_cif[key][2]
            if volume_per_formula < existing_volume:
                key_to_cif[key] = (cif_id, cif_str, volume_per_formula)
    
    return [(cid, cif) for cid, cif, _ in key_to_cif.values()]
```

#### 6.1.2 标准化与增强

**预处理步骤**（`bin/preprocess.py`）：

1. **对称化**：使用 pymatgen 的 `SpacegroupAnalyzer` 获取对称化结构
2. **添加原子属性**：
   ```python
   _atom_type_symbol
   _atom_type_electronegativity
   _atom_type_radius
   _atom_type_ionic_radius
   ```
3. **标准化空间群符号**：统一为 Hermann-Mauguin 记号
4. **数字精度**：统一小数位数
5. **验证**：确保 CIF 可解析

**增强技术**：
```python
def augment_cif(cif_str):
    structure = Structure.from_str(cif_str, fmt="cif")
    
    # 1. 对称化
    sga = SpacegroupAnalyzer(structure, symprec=0.1)
    symmetrized = sga.get_symmetrized_structure()
    
    # 2. 转换回 CIF
    cif_str = str(CifWriter(symmetrized))
    
    # 3. 添加原子属性
    cif_str = add_atomic_props_block(cif_str)
    
    # 4. 标准化格式
    cif_str = standardize_format(cif_str)
    
    return cif_str
```

### 6.2 训练技巧

#### 6.2.1 数据加载优化

```python
# 使用内存映射的 NumPy 数组
train_data = np.memmap('tokens/train.bin', dtype=np.uint16, mode='r')

# 高效批次采样
def get_batch(split, batch_size, block_size):
    data = train_data if split == 'train' else val_data
    ix = torch.randint(len(data) - block_size, (batch_size,))
    x = torch.stack([torch.from_numpy((data[i:i+block_size]).astype(np.int64)) for i in ix])
    y = torch.stack([torch.from_numpy((data[i+1:i+1+block_size]).astype(np.int64)) for i in ix])
    return x.to(device), y.to(device)
```

#### 6.2.2 CIF 对齐采样

**问题**：随机截断可能破坏 CIF 结构

**解决方案**：从 CIF 起始位置采样
```python
# 预先识别所有 CIF 起始位置
starts = []
for i, token_id in enumerate(train_data):
    if id_to_token[token_id] == 'data_':
        starts.append(i)

# 训练时从起始位置采样
def get_batch_aligned(batch_size, block_size, starts):
    ix = [random.choice(starts) for _ in range(batch_size)]
    x = torch.stack([torch.from_numpy((train_data[i:i+block_size]).astype(np.int64)) for i in ix])
    y = torch.stack([torch.from_numpy((train_data[i+1:i+1+block_size]).astype(np.int64)) for i in ix])
    return x, y
```

#### 6.2.3 学习率调度

```python
# Cosine Decay with Warmup
def get_lr(it, warmup_iters, lr_decay_iters, learning_rate, min_lr):
    # 1) linear warmup
    if it < warmup_iters:
        return learning_rate * it / warmup_iters
    # 2) constant
    if it > lr_decay_iters:
        return min_lr
    # 3) cosine decay
    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)
    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio))
    return min_lr + coeff * (learning_rate - min_lr)
```

### 6.3 生成策略

#### 6.3.1 Temperature Sampling

**原理**：调整 softmax 温度控制随机性
```python
logits = logits / temperature
probs = F.softmax(logits, dim=-1)
```

**效果**：
- `temperature < 1.0`：更保守，倾向高概率 token
- `temperature = 1.0`：标准分布
- `temperature > 1.0`：更随机，增加多样性

**推荐值**：
- 追求稳定性：0.6 - 0.7
- 平衡：0.75 - 0.85
- 追求多样性：0.9 - 1.2

#### 6.3.2 Top-K Sampling

**原理**：只考虑概率最高的 K 个 token
```python
if top_k is not None:
    v, _ = torch.topk(logits, min(top_k, logits.size(-1)))
    logits[logits < v[:, [-1]]] = -float('Inf')
probs = F.softmax(logits, dim=-1)
```

**效果**：
- 小 `top_k`（5-10）：保守，高质量
- 中等 `top_k`（10-30）：平衡
- 大 `top_k`（>30）：多样，可能不稳定

#### 6.3.3 核采样（Nucleus Sampling / Top-P）

虽然当前代码未实现，但可以添加：
```python
def top_p_sampling(logits, top_p=0.9):
    sorted_logits, sorted_indices = torch.sort(logits, descending=True)
    cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)
    
    # 移除累积概率超过 top_p 的 token
    sorted_indices_to_remove = cumulative_probs > top_p
    sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()
    sorted_indices_to_remove[..., 0] = 0
    
    indices_to_remove = sorted_indices_to_remove.scatter(1, sorted_indices, sorted_indices_to_remove)
    logits[indices_to_remove] = -float('Inf')
    return logits
```

### 6.4 后处理技术

#### 6.4.1 对称操作替换

**问题**：模型生成的对称操作可能不准确

**解决方案**：根据空间群替换为标准操作
```python
def replace_symmetry_operators(cif_str, space_group_symbol):
    # 从数据库获取标准对称操作
    from pymatgen.symmetry.groups import SpaceGroup
    sg = SpaceGroup(space_group_symbol)
    
    # 替换 CIF 中的 _symmetry_equiv_pos_as_xyz 块
    # ...
    return corrected_cif_str
```

#### 6.4.2 体积一致性检查

```python
def check_volume_consistency(cif_str):
    # 提取晶格参数
    a = extract_numeric_property(cif_str, "_cell_length_a")
    b = extract_numeric_property(cif_str, "_cell_length_b")
    c = extract_numeric_property(cif_str, "_cell_length_c")
    alpha = extract_numeric_property(cif_str, "_cell_angle_alpha")
    beta = extract_numeric_property(cif_str, "_cell_angle_beta")
    gamma = extract_numeric_property(cif_str, "_cell_angle_gamma")
    
    # 计算体积
    calculated_volume = get_unit_cell_volume(a, b, c, alpha, beta, gamma)
    
    # 提取声明的体积
    stated_volume = extract_volume(cif_str)
    
    # 检查一致性（允许 1% 误差）
    return abs(calculated_volume - stated_volume) / stated_volume < 0.01
```

---

## 7. 模型训练与优化

### 7.1 训练数据集

#### 7.1.1 主数据集统计

| 集合 | CIF 数量 | 比例 | 用途 |
|-----|---------|------|-----|
| 原始 | 3,551,492 | 100% | - |
| 去重后 | 2,285,914 | 64.4% | - |
| 预处理后 | 2,285,719 | 64.4% | - |
| **训练集** | **2,047,889** | **89.6%** | 模型训练 |
| **验证集** | **227,544** | **10.0%** | 超参数调优 |
| **测试集** | **10,286** | **0.4%** | 最终评估 |

#### 7.1.2 数据来源

- **Materials Project**：约 140,000 个结构（DFT 优化）
- **OQMD**：约 800,000 个结构（高通量 DFT）
- **NOMAD**：约 2,600,000 个结构（各种来源）

#### 7.1.3 专用数据集

**Perov-5**：钙钛矿专用
- 训练：5,329 个结构
- 验证：1,776 个结构
- 测试：1,784 个结构

**Carbon-24**：碳材料专用
- 训练：5,116 个结构
- 验证：1,706 个结构
- 测试：1,706 个结构

**MP-20**：Materials Project 子集
- 训练：16,398 个结构
- 验证：8,199 个结构
- 测试：8,199 个结构

### 7.2 训练策略

#### 7.2.1 小型模型配置

```yaml
# config/crystallm_v1_small.yaml
n_layer: 12
n_head: 12
n_embd: 768
block_size: 2048
vocab_size: 371

batch_size: 64
gradient_accumulation_steps: 40  # 有效 batch size = 2560
max_iters: 600000
learning_rate: 6e-4
warmup_iters: 2000

device: cuda
dtype: bfloat16
compile: True
```

**训练时间**：
- 单个 A100 GPU：约 2-3 周
- 4× A100 GPU：约 4-5 天

#### 7.2.2 大型模型配置

```yaml
# config/crystallm_v1_large.yaml
n_layer: 24
n_head: 16
n_embd: 1024
block_size: 2048
vocab_size: 371

batch_size: 32
gradient_accumulation_steps: 80  # 有效 batch size = 2560
max_iters: 600000
learning_rate: 6e-4
```

**训练时间**：
- 单个 A100 GPU：约 6-8 周
- 8× A100 GPU：约 7-10 天

#### 7.2.3 领域适应（Fine-tuning）

从通用模型微调到特定领域：

```bash
# 使用通用模型作为起点
python bin/train.py \
    --config=config/finetune_perovskite.yaml \
    init_from=resume \
    out_dir=crystallm_v1_small \
    dataset=tokens_perov_5 \
    max_iters=50000 \
    learning_rate=1e-4  # 较低学习率
```

**优势**：
- 更快收敛（10-20 倍）
- 需要更少数据（数千个样本 vs 数百万）
- 保留通用知识

### 7.3 评估指标

#### 7.3.1 训练过程指标

```python
# 训练损失
train_loss = cross_entropy_loss(predictions, targets)

# 验证损失
val_loss = evaluate_model(model, val_data)

# 困惑度（Perplexity）
perplexity = torch.exp(val_loss)

# 模型 FLOPs 利用率（MFU）
mfu = actual_flops / theoretical_peak_flops
```

典型曲线：
```
iter 0:     loss 6.5234  (随机初始化)
iter 1000:  loss 3.2156
iter 10000: loss 2.1234
iter 100000: loss 1.5678
iter 600000: loss 1.2345  (收敛)
```

#### 7.3.2 生成质量指标

| 指标 | 小型模型 | 大型模型 | 说明 |
|-----|---------|---------|-----|
| 空间群一致性 | 98.9% | 99.2% | 生成结构符合声明空间群 |
| 原子位点一致性 | 99.4% | 99.6% | 对称重数正确 |
| 键长合理性 | 0.988 ± 0.070 | 0.991 ± 0.065 | 平均合理性分数 |
| 综合有效性 | 94.0% | 95.2% | 通过所有检查 |
| 平均生成长度 | 332 tokens | 335 tokens | 有效 CIF 的平均长度 |

---

## 8. 高级功能详解

### 8.1 MCTS 深度解析

#### 8.1.1 算法流程

**蒙特卡洛树搜索**用于优化生成过程：

```
根节点（提示）
    │
    ├─ 选择（Selection）
    │  使用 UCT/PUCT 公式选择最有前景的节点
    │  UCT = Q(s,a) / N(s,a) + c * sqrt(ln(N(s)) / N(s,a))
    │
    ├─ 扩展（Expansion）
    │  生成 tree_width 个子节点（下一个 token）
    │  基于模型的概率分布采样
    │
    ├─ 模拟（Simulation/Rollout）
    │  从子节点完整生成到 CIF 结尾
    │  使用标准采样（temperature + top-k）
    │
    └─ 反向传播（Backpropagation）
       评估生成的 CIF 质量
       更新路径上所有节点的价值
```

#### 8.1.2 选择策略

**PUCT（Predictor + UCT）**：
```python
def puct_score(node, parent, c_puct):
    Q = node.total_reward / node.visit_count  # 平均奖励
    U = c_puct * node.prior_prob * math.sqrt(parent.visit_count) / (1 + node.visit_count)
    return Q + U
```

**UCT（Upper Confidence Bound for Trees）**：
```python
def uct_score(node, parent, c):
    exploitation = node.total_reward / node.visit_count
    exploration = c * math.sqrt(math.log(parent.visit_count) / node.visit_count)
    return exploitation + exploration
```

**贪婪选择**：
```python
def greedy_score(node, epsilon):
    if random.random() < epsilon:
        return random.random()  # 探索
    else:
        return node.total_reward / node.visit_count  # 利用
```

#### 8.1.3 奖励函数设计

```python
def calculate_reward(cif_str, scorer, all_scores):
    # 1. 快速验证
    if not is_sensible(cif_str):
        return 0.0
    
    # 2. 结构验证
    is_valid, msg, bond_score = validate_structure(cif_str)
    if not is_valid:
        return 0.1  # 小奖励，避免完全放弃
    
    # 3. 外部评分（如能量）
    energy = scorer.score(cif_str)
    
    # 4. 归一化奖励
    # 使用 sigmoid 将分数映射到 [0, 1]
    all_scores.append(energy)
    mu = np.mean(all_scores)
    sigma = np.std(all_scores)
    normalized = 1 / (1 + math.exp(reward_k * (energy - mu) / sigma))
    
    return normalized
```

#### 8.1.4 上下文感知树构建

**问题**：某些 token 序列总是一起出现（如 `_cell_length_a 3.85`）

**解决方案**：识别"必然"序列，跳过不必要的分支
```python
class ContextSensitiveTreeBuilder:
    def should_branch(self, context, next_token):
        # 如果上下文强烈暗示下一个 token（概率 > 0.99），直接添加
        logits = model(context)
        probs = F.softmax(logits, dim=-1)
        max_prob = probs.max()
        
        if max_prob > 0.99:
            return False  # 不分支，直接选择
        return True  # 正常分支
```

### 8.2 嵌入分析

#### 8.2.1 提取嵌入向量

```bash
# 提取原子嵌入
python bin/extract_embeddings.py \
    out/my_model \
    --dataset tokens_v1_all.tar.gz \
    --out atom_embeddings.csv \
    --type atom

# 提取空间群嵌入
python bin/extract_embeddings.py \
    out/my_model \
    --dataset tokens_v1_all.tar.gz \
    --out spacegroup_embeddings.csv \
    --type spacegroup
```

#### 8.2.2 嵌入空间可视化

```python
# embedding_analysis.py
from crystallm import embeddings_from_csv
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt

# 加载嵌入
embeddings = embeddings_from_csv("atom_embeddings.csv")

# 提取原子符号和向量
atoms = list(embeddings.keys())
vectors = np.array([embeddings[atom] for atom in atoms])

# t-SNE 降维
tsne = TSNE(n_components=2, random_state=42)
coords_2d = tsne.fit_transform(vectors)

# 可视化
plt.figure(figsize=(12, 10))
plt.scatter(coords_2d[:, 0], coords_2d[:, 1], alpha=0.5)

for i, atom in enumerate(atoms):
    plt.annotate(atom, (coords_2d[i, 0], coords_2d[i, 1]))

plt.title("t-SNE Visualization of Atom Embeddings")
plt.xlabel("t-SNE 1")
plt.ylabel("t-SNE 2")
plt.savefig("atom_embeddings_tsne.png", dpi=300)
```

**发现**：
- 相似化学性质的原子在嵌入空间中聚集
- 过渡金属形成明显的簇
- 碱金属和碱土金属分离
- 卤素元素聚集

#### 8.2.3 化学相似性分析

```python
from scipy.spatial.distance import cosine

def chemical_similarity(atom1, atom2, embeddings):
    vec1 = embeddings[atom1]
    vec2 = embeddings[atom2]
    return 1 - cosine(vec1, vec2)

# 找到与 Fe 最相似的元素
similarities = {atom: chemical_similarity("Fe", atom, embeddings) 
                for atom in atoms if atom != "Fe"}
top_similar = sorted(similarities.items(), key=lambda x: x[1], reverse=True)[:10]
print("Most similar to Fe:", top_similar)
# 输出可能：[('Co', 0.95), ('Ni', 0.93), ('Mn', 0.91), ...]
```

### 8.3 外部评分器集成

#### 8.3.1 ZMQ 评分器架构

**服务端**（运行 ML 模型）：
```python
# alignn_server.py
import zmq
from alignn.ff.ff import AlignnAtomwiseCalculator, default_path

# 初始化 ALIGNN 模型
calc = AlignnAtomwiseCalculator(path=default_path())

# 设置 ZMQ 服务器
context = zmq.Context()
socket = context.socket(zmq.REP)
socket.bind("tcp://*:5555")

print("ALIGNN scoring server running on port 5555")

while True:
    # 接收 CIF 字符串
    cif_str = socket.recv_string()
    
    try:
        # 预测能量
        from pymatgen.core import Structure
        structure = Structure.from_str(cif_str, fmt="cif")
        
        # ALIGNN 预测
        atoms = structure.to_ase_atoms()
        atoms.calc = calc
        energy = atoms.get_potential_energy()
        
        # 返回分数
        socket.send_json({"energy": energy, "success": True})
    except Exception as e:
        socket.send_json({"error": str(e), "success": False})
```

**客户端**（CrystaLLM MCTS）：
```python
class ZMQScorer(CIFScorer):
    def __init__(self, host="localhost", port=5555):
        self.context = zmq.Context()
        self.socket = self.context.socket(zmq.REQ)
        self.socket.connect(f"tcp://{host}:{port}")
        self.socket.setsockopt(zmq.RCVTIMEO, 30000)  # 30s timeout
    
    def score(self, cif_str):
        self.socket.send_string(cif_str)
        response = self.socket.recv_json()
        
        if response["success"]:
            return response["energy"]
        else:
            raise ValueError(f"Scoring failed: {response['error']}")
```

#### 8.3.2 自定义评分器

```python
from crystallm import CIFScorer

class MyCustomScorer(CIFScorer):
    def __init__(self):
        # 初始化你的模型
        self.model = load_my_model()
    
    def score(self, cif_str):
        # 1. 解析 CIF
        from pymatgen.io.cif import CifParser
        parser = CifParser.from_string(cif_str)
        structure = parser.get_structures()[0]
        
        # 2. 特征提取
        features = extract_features(structure)
        
        # 3. 预测
        score = self.model.predict(features)
        
        return score
```

使用自定义评分器：
```python
from crystallm import MCTSSampler, MCTSEvaluator

scorer = MyCustomScorer()
evaluator = MCTSEvaluator(scorer, tokenizer)
sampler = MCTSSampler(model, tokenizer, evaluator, ...)
```

---

## 9. 实际应用案例

### 9.1 案例 1：钙钛矿太阳能电池材料设计

#### 9.1.1 背景

目标：设计稳定、高效的钙钛矿太阳能电池材料

要求：
- ABX₃ 结构
- Goldschmidt 容忍因子 0.8-1.0
- 合适的带隙（1.1-1.6 eV）
- 热力学稳定

#### 9.1.2 工作流程

```bash
# 第 1 步：生成候选结构
python examples/generate_perovskites.py \
    --model crystallm_perov_5_small \
    --compositions "CsPbI3:Pm-3m,CsPbBr3:Pm-3m,CsPbCl3:Pm-3m,CsSnI3:Pnma" \
    --num-samples 100 \
    --temperature 0.7 \
    --output solar_cell_candidates/

# 第 2 步：初步筛选
python examples/analyze_perovskites.py \
    --input solar_cell_candidates/ \
    --output analysis/ \
    --min-quality 85

# 第 3 步：容忍因子筛选
python << EOF
import pandas as pd

df = pd.read_csv('analysis/analysis_full.csv')

# 筛选条件
candidates = df[
    (df['quality_score'] >= 85) &
    (df['tolerance_factor'] >= 0.85) &
    (df['tolerance_factor'] <= 0.95) &
    (df['is_valid'] == True)
]

candidates.to_csv('solar_cell_filtered.csv', index=False)
print(f"Found {len(candidates)} candidates")
EOF

# 第 4 步：DFT 计算（使用 VASP/Quantum ESPRESSO）
# 这里需要外部 DFT 软件
# 计算：能量、带隙、电子结构

# 第 5 步：最终选择
# 基于 DFT 结果选择最佳候选
```

#### 9.1.3 结果示例

| 组成 | 空间群 | 容忍因子 | 质量分数 | DFT 带隙 | 稳定性 |
|-----|--------|---------|---------|---------|--------|
| CsPbI₃ | Pm-3m | 0.89 | 92.3 | 1.48 eV | 稳定 |
| CsPbBr₃ | Pm-3m | 0.87 | 94.1 | 2.25 eV | 稳定 |
| CsSnI₃ | Pnma | 0.92 | 88.7 | 1.30 eV | 亚稳 |

### 9.2 案例 2：锂离子电池正极材料探索

#### 9.2.1 目标

发现新型锂离子电池正极材料

体系：Li-M-O（M = Co, Ni, Mn, Fe）

#### 9.2.2 实施

```python
# battery_material_search.py
import itertools

# 定义搜索空间
Li_ratios = [1, 2, 3]
M_atoms = ['Co', 'Ni', 'Mn', 'Fe']
O_ratios = [2, 3, 4]

# 生成所有可能的组成
compositions = []
for li, m, o in itertools.product(Li_ratios, M_atoms, O_ratios):
    comp = f"Li{li}{m}{o}O{o*2}"  # 简化示例
    compositions.append(comp)

# 批量生成
for comp in compositions:
    subprocess.run([
        "python", "bin/sample.py",
        "out_dir=crystallm_v1_small",
        f"start=$'data_{comp}\\n'",
        "num_samples=50",
        "temperature=0.75"
    ])

# 使用 MCTS + 能量评分
# （需要集成 M3GNet 或 ALIGNN 能量预测）
```

### 9.3 案例 3：催化剂晶相工程

#### 9.3.1 背景

TiO₂ 有多种晶型（锐钛矿、金红石、板钛矿），催化性能不同

#### 9.3.2 应用

```bash
# 生成 TiO2 的不同晶型
python bin/make_prompts.py \
    --compositions "TiO2" \
    --spacegroups "I41/amd,P42/mnm,Pbca,Cmcm" \
    --output tio2_prompts/

python bin/generate_cifs.py \
    --model crystallm_v1_small \
    --prompts tio2_prompts/ \
    --num-gens 30 \
    --output tio2_phases/

# 使用 MCTS 优化表面能
python bin/mcts.py \
    out_dir=crystallm_v1_small \
    start=FILE:tio2_prompts/TiO2_anatase.txt \
    num_simulations=500 \
    scorer=surface_energy  # 自定义评分器
```

### 9.4 案例 4：高通量虚拟筛选

#### 9.4.1 场景

从 10,000 个候选组成中筛选潜在的超导体

#### 9.4.2 流程

```python
# high_throughput_screening.py
from multiprocessing import Pool
import pandas as pd

# 1. 读取候选列表
candidates = pd.read_csv('candidate_compositions.csv')['composition'].tolist()

# 2. 并行生成
def generate_and_evaluate(composition):
    # 生成结构
    structures = generate_structures(composition, num_samples=10)
    
    # 快速筛选
    valid = [s for s in structures if is_valid(s)]
    
    if not valid:
        return None
    
    # ML 预测超导 Tc
    best_structure = max(valid, key=lambda s: predict_tc(s))
    
    return {
        'composition': composition,
        'structure': best_structure,
        'predicted_tc': predict_tc(best_structure)
    }

# 并行处理
with Pool(32) as pool:
    results = pool.map(generate_and_evaluate, candidates)

# 筛选高 Tc 候选
high_tc = [r for r in results if r and r['predicted_tc'] > 20]  # Tc > 20K
high_tc_df = pd.DataFrame(high_tc)
high_tc_df.to_csv('high_tc_candidates.csv')
```

---

## 10. 性能评估与基准测试

### 10.1 基准数据集

项目提供了 4 个基准测试：

1. **Perov-5**：5 种钙钛矿（CaTiO₃, SrTiO₃, BaTiO₃, PbTiO₃, LaAlO₃）
2. **Carbon-24**：24 种碳材料
3. **MP-20**：20 种来自 Materials Project 的多样化材料
4. **MPTS-52**：52 种材料（用于测试模型泛化）

### 10.2 评估指标

#### 10.2.1 有效性（Validity）

**定义**：生成的 CIF 通过所有验证检查

**检查项目**：
- 公式一致性
- 原子位点重数一致性
- 键长合理性（≥ 1.0）
- 空间群一致性

**结果**（crystallm_v1_small 在测试集上）：
- 有效率：94.0%
- 空间群一致性：98.9%
- 键长合理性：0.988 ± 0.070

#### 10.2.2 唯一性（Uniqueness）

**定义**：生成结构之间的去重

**方法**：使用 pymatgen 的 `StructureMatcher`
```python
from pymatgen.analysis.structure_matcher import StructureMatcher

matcher = StructureMatcher(ltol=0.2, stol=0.3, angle_tol=5)
unique_structures = []

for structure in generated_structures:
    is_unique = True
    for unique_struct in unique_structures:
        if matcher.fit(structure, unique_struct):
            is_unique = False
            break
    if is_unique:
        unique_structures.append(structure)

uniqueness_rate = len(unique_structures) / len(generated_structures)
```

**典型结果**：
- 低温度（0.6）：唯一性 ~ 30-40%（更保守）
- 中等温度（0.8）：唯一性 ~ 60-70%
- 高温度（1.0）：唯一性 ~ 85-95%（更多样）

#### 10.2.3 新颖性（Novelty）

**定义**：生成结构不在训练集中

**计算**：
```python
def is_novel(generated_structure, training_set, matcher):
    for training_struct in training_set:
        if matcher.fit(generated_structure, training_struct):
            return False
    return True

novelty_rate = sum(is_novel(s, training_set) for s in generated) / len(generated)
```

**结果**：
- 有条件生成（指定组成+空间群）：新颖性 ~ 5-15%
- 无条件生成：新颖性 ~ 40-60%

### 10.3 基准测试结果

#### 10.3.1 Perov-5 基准

| 模型 | 有效率 | 唯一性 | 新颖性 | 匹配率* |
|-----|--------|--------|--------|---------|
| crystallm_v1_small | 94.2% | 68.3% | 8.7% | 96.5% |
| crystallm_v1_large | 95.8% | 71.2% | 12.1% | 97.8% |
| crystallm_perov_5_small | 97.1% | 65.4% | 6.3% | 98.9% |

*匹配率：生成的组成和空间群与提示一致

#### 10.3.2 与其他方法对比

| 方法 | 有效率 | 生成速度 | 需要训练 |
|-----|--------|---------|---------|
| **CrystaLLM** | **94%** | **秒级** | **是** |
| CDVAE | 87% | 分钟级 | 是 |
| PGCGM | 78% | 小时级 | 否 |
| 进化算法 | 91% | 天级 | 否 |

### 10.4 运行基准测试

```bash
# 下载基准数据集
python bin/download.py prompts_perov_5_test.tar.gz
tar xvf prompts_perov_5_test.tar.gz

# 生成结构
python bin/generate_cifs.py \
    --model crystallm_perov_5_small \
    --prompts prompts_perov_5_test/ \
    --num-gens 1 \
    --output gen_perov_5/ \
    --device cuda

# 评估
python bin/evaluate_cifs.py gen_perov_5/ -o perov_5_eval.csv

# 计算有效性、唯一性、新颖性
python bin/benchmark_metrics.py \
    --generated gen_perov_5/ \
    --training cifs_perov_5_train.pkl.gz \
    --output benchmark_results.json
```

详细基准测试指南：[BENCHMARKING.md](BENCHMARKING.md)

---

## 11. 扩展与定制

### 11.1 添加新的 Token

**场景**：支持新的 CIF 关键词或扩展元素

```python
# 修改 crystallm/_tokenizer.py

# 添加新元素（如超重元素）
NEW_ATOMS = ["Og", "Ts", "Nh"]  # Oganesson, Tennessine, Nihonium

# 添加新关键词
NEW_KEYWORDS = [
    "_atom_site_aniso_U_11",
    "_atom_site_aniso_U_22",
    # ...
]

# 更新 CIFTokenizer 类
class CIFTokenizer:
    def __init__(self):
        self._tokens = list(self.atoms())
        self._tokens.extend(NEW_ATOMS)  # 添加新原子
        self._tokens.extend(self.keywords())
        self._tokens.extend(NEW_KEYWORDS)  # 添加新关键词
        # ...
```

**注意**：添加 token 后需要重新训练模型！

### 11.2 自定义验证函数

```python
# custom_validation.py
from crystallm import is_valid

def is_my_material_valid(cif_str):
    # 基础验证
    if not is_valid(cif_str):
        return False
    
    # 自定义检查 1：特定元素要求
    from crystallm import extract_data_formula
    from pymatgen.core import Composition
    
    formula = extract_data_formula(cif_str)
    comp = Composition(formula)
    
    # 必须包含 Li
    if 'Li' not in comp:
        return False
    
    # 自定义检查 2：晶格参数范围
    from crystallm import extract_numeric_property
    a = extract_numeric_property(cif_str, "_cell_length_a")
    if not (3.0 < a < 10.0):
        return False
    
    # 自定义检查 3：能量稳定性（需要 ML 模型）
    energy = predict_energy(cif_str)
    if energy > -2.0:  # eV/atom
        return False
    
    return True
```

### 11.3 集成到其他工作流

#### 11.3.1 与 ASE 集成

```python
# ase_integration.py
from ase import Atoms
from pymatgen.io.cif import CifParser
from pymatgen.io.ase import AseAtomsAdaptor

# CrystaLLM 生成 CIF
cif_str = generate_cif(prompt)

# 转换为 pymatgen Structure
parser = CifParser.from_string(cif_str)
structure = parser.get_structures()[0]

# 转换为 ASE Atoms
adaptor = AseAtomsAdaptor()
atoms = adaptor.get_atoms(structure)

# 使用 ASE 进行优化
from ase.optimize import BFGS
from ase.calculators.emt import EMT  # 示例计算器

atoms.calc = EMT()
opt = BFGS(atoms)
opt.run(fmax=0.05)

# 优化后的结构
optimized_structure = adaptor.get_structure(atoms)
```

#### 11.3.2 与 VASP 集成

```python
# vasp_workflow.py
from pymatgen.io.vasp import Poscar, Incar, Kpoints, VaspInput
from pymatgen.io.cif import CifParser

# 生成结构
cif_str = generate_cif(prompt)
parser = CifParser.from_string(cif_str)
structure = parser.get_structures()[0]

# 创建 VASP 输入文件
poscar = Poscar(structure)
poscar.write_file("POSCAR")

incar = Incar({
    'SYSTEM': 'CrystaLLM generated',
    'PREC': 'Accurate',
    'ENCUT': 520,
    'ISMEAR': 0,
    'SIGMA': 0.05,
    'EDIFF': 1e-6,
    'ISIF': 3,  # 优化体积和形状
})
incar.write_file("INCAR")

kpoints = Kpoints.automatic_density(structure, 1000)
kpoints.write_file("KPOINTS")

# 运行 VASP
import subprocess
subprocess.run(["mpirun", "-np", "16", "vasp_std"])
```

#### 11.3.3 与 PyTorch Geometric 集成

```python
# gnn_integration.py
import torch
from torch_geometric.data import Data
from pymatgen.io.cif import CifParser

# 生成结构
cif_str = generate_cif(prompt)
parser = CifParser.from_string(cif_str)
structure = parser.get_structures()[0]

# 转换为图
def structure_to_graph(structure, cutoff=5.0):
    # 节点特征：原子编号
    x = torch.tensor([site.specie.Z for site in structure], dtype=torch.float)
    
    # 边：距离 < cutoff 的原子对
    edge_index = []
    edge_attr = []
    
    for i, site_i in enumerate(structure):
        for j, site_j in enumerate(structure):
            if i != j:
                dist = site_i.distance(site_j)
                if dist < cutoff:
                    edge_index.append([i, j])
                    edge_attr.append([dist])
    
    edge_index = torch.tensor(edge_index, dtype=torch.long).t()
    edge_attr = torch.tensor(edge_attr, dtype=torch.float)
    
    # 全局特征：晶格参数
    lattice = structure.lattice
    u = torch.tensor([
        lattice.a, lattice.b, lattice.c,
        lattice.alpha, lattice.beta, lattice.gamma
    ], dtype=torch.float)
    
    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, u=u)

# 创建图数据
graph = structure_to_graph(structure)

# 使用 GNN 模型预测性质
from torch_geometric.nn import GCNConv, global_mean_pool

class CrystalGNN(torch.nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = GCNConv(1, 64)
        self.conv2 = GCNConv(64, 64)
        self.lin = torch.nn.Linear(64, 1)
    
    def forward(self, data):
        x = self.conv1(data.x.unsqueeze(1), data.edge_index)
        x = torch.relu(x)
        x = self.conv2(x, data.edge_index)
        x = global_mean_pool(x, torch.zeros(x.size(0), dtype=torch.long))
        return self.lin(x)

model = CrystalGNN()
prediction = model(graph)
```

### 11.4 创建 Web 界面

```python
# web_app.py
from flask import Flask, request, jsonify, render_template
import torch
from crystallm import GPT, CIFTokenizer

app = Flask(__name__)

# 加载模型
model = GPT.from_pretrained('crystallm_v1_small/ckpt.pt')
model.eval()
tokenizer = CIFTokenizer()

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/generate', methods=['POST'])
def generate():
    data = request.json
    composition = data.get('composition')
    spacegroup = data.get('spacegroup', None)
    num_samples = data.get('num_samples', 5)
    
    # 创建提示
    if spacegroup:
        prompt = f"data_{composition}\n_symmetry_space_group_name_H-M {spacegroup}\n"
    else:
        prompt = f"data_{composition}\n"
    
    # 生成
    results = []
    for _ in range(num_samples):
        cif_str = generate_cif(model, tokenizer, prompt)
        
        # 验证
        is_valid_structure = is_valid(cif_str)
        
        results.append({
            'cif': cif_str,
            'valid': is_valid_structure
        })
    
    return jsonify(results)

@app.route('/visualize', methods=['POST'])
def visualize():
    cif_str = request.json.get('cif')
    
    # 生成 3D 可视化（使用 py3Dmol 或 Crystal Toolkit）
    # ...
    
    return jsonify({'visualization': '...'})

if __name__ == '__main__':
    app.run(debug=True, port=5000)
```

---

## 12. 技术优势与局限

### 12.1 优势

#### 12.1.1 速度与效率

- **生成速度**：GPU 上秒级生成（vs. DFT 的小时-天级）
- **批量处理**：轻松并行化，适合高通量筛选
- **快速迭代**：即时获得反馈，加速设计循环

#### 12.1.2 灵活性

- **条件生成**：可指定组成、空间群
- **无条件生成**：探索未知结构
- **可控多样性**：通过温度和 top-k 调整

#### 12.1.3 物理合理性

- **高有效率**：94% 的结构通过验证
- **对称性正确**：98.9% 空间群一致性
- **化学合理**：学习到元素共现模式

#### 12.1.4 可扩展性

- **易于集成**：标准 Python 接口
- **可定制**：支持自定义验证和评分
- **模块化**：各组件独立可替换

### 12.2 局限

#### 12.2.1 训练数据依赖

- **偏向训练分布**：难以生成与训练数据非常不同的结构
- **数据质量影响**：训练数据错误会传播
- **稀有体系表现差**：训练样本少的材料系统生成质量较低

**缓解策略**：
- 领域特定微调
- 数据增强
- 混合方法（LLM + 物理约束）

#### 12.2.2 物理保证

- **非确定性**：无法保证生成结构稳定
- **能量未优化**：生成的结构可能不是能量最小值
- **需要后续验证**：重要应用必须 DFT 验证

**缓解策略**：
- MCTS + 能量评分
- 后处理优化（如 ASE 优化）
- 多样性生成 + 筛选

#### 12.2.3 长序列挑战

- **上下文窗口限制**：block_size = 2048 tokens
- **大结构可能截断**：复杂晶胞可能超出限制
- **长依赖关系**：远距离信息传播受限

**缓解策略**：
- 增大 block_size（需要更多内存）
- 分层生成策略
- 专注于特定材料系统

#### 12.2.4 可解释性

- **黑盒模型**：难以解释为什么生成特定结构
- **调试困难**：错误生成难以追溯原因
- **信任问题**：关键应用需要额外验证

**缓解策略**：
- 嵌入分析（理解学到的化学知识）
- 注意力可视化
- 对比实验（控制变量）

### 12.3 未来方向

#### 12.3.1 模型改进

- **更大模型**：GPT-3 规模（数十亿参数）
- **多模态**：结合文本描述和性质预测
- **强化学习**：直接优化物理性质

#### 12.3.2 方法创新

- **扩散模型**：用于晶体结构生成
- **变分自编码器**：学习晶体空间的连续表示
- **图神经网络 + LLM**：结合几何和序列信息

#### 12.3.3 应用扩展

- **逆向设计**：根据目标性质生成结构
- **缺陷工程**：生成含点缺陷、界面的结构
- **动力学**：生成分子动力学轨迹

#### 12.3.4 计算集成

- **端到端流程**：生成 → DFT → 分析 → 反馈
- **主动学习**：迭代改进生成策略
- **云平台**：Materials Studio 即服务

---

## 13. 总结

### 13.1 核心要点

1. **创新方法**：CrystaLLM 首次成功将 LLM 技术应用于晶体结构生成，达到业界领先水平

2. **实用性强**：
   - 高有效率（94%）和准确率（98.9% 空间群一致性）
   - 快速生成（秒级）
   - 易于使用和集成

3. **广泛应用**：
   - 材料发现（钙钛矿、电池材料、催化剂）
   - 结构预测
   - 高通量筛选
   - 教育和研究

4. **开放生态**：
   - 完整开源
   - 预训练模型可用
   - 详细文档和示例
   - 活跃社区支持

### 13.2 推荐使用场景

**适合使用 CrystaLLM**：
- ✅ 快速生成候选材料结构
- ✅ 探索特定材料体系（如钙钛矿）
- ✅ 高通量虚拟筛选
- ✅ 结构预测起点
- ✅ 教学和演示

**不适合/需谨慎**：
- ❌ 要求极高精度的应用（需 DFT 验证）
- ❌ 完全未知的材料系统（训练数据外）
- ❌ 关键工程应用（需实验验证）
- ⚠️ 复杂缺陷结构（当前版本支持有限）
- ⚠️ 超大晶胞（> 2048 tokens）

### 13.3 开始使用

**快速开始**：
```bash
# 1. 安装
git clone https://github.com/lantunes/CrystaLLM.git
cd CrystaLLM
pip install -r requirements.txt
pip install -e .

# 2. 下载模型
python bin/download.py crystallm_v1_small.tar.gz
tar xvf crystallm_v1_small.tar.gz

# 3. 生成第一个结构
python bin/make_prompt_file.py "NaCl" prompt.txt --spacegroup "Fm-3m"
python bin/sample.py \
    out_dir=crystallm_v1_small \
    start=FILE:prompt.txt \
    num_samples=5 \
    device=cuda
```

### 13.4 参考资源

- **主仓库**：https://github.com/lantunes/CrystaLLM
- **论文**：[Nature Communications (2024)](https://www.nature.com/articles/s41467-024-54639-7)
- **数据和模型**：[Zenodo](https://zenodo.org/records/10642388)
- **文档**：
  - [README.md](README.md) - 主文档
  - [PEROVSKITE_GENERATION_GUIDE.md](PEROVSKITE_GENERATION_GUIDE.md) - 钙钛矿指南
  - [BENCHMARKING.md](BENCHMARKING.md) - 基准测试
  - [examples/README.md](examples/README.md) - 示例脚本

### 13.5 引用

如果您在研究中使用 CrystaLLM，请引用：

```bibtex
@article{antunes2024crystal,
  title={Crystal structure generation with autoregressive large language modeling},
  author={Antunes, Luis M and Butler, Keith T and Grau-Crespo, Ricardo},
  journal={Nature Communications},
  volume={15},
  number={1},
  pages={10570},
  year={2024},
  publisher={Nature Publishing Group}
}
```

---

## 附录

### A. 术语表

- **CIF**：Crystallographic Information File，晶体学信息文件
- **GPT**：Generative Pre-trained Transformer，生成式预训练 Transformer
- **MCTS**：Monte Carlo Tree Search，蒙特卡洛树搜索
- **DFT**：Density Functional Theory，密度泛函理论
- **Token**：模型处理的最小单位（原子、数字、关键词等）
- **Space Group**：空间群，描述晶体对称性的数学群
- **Perovskite**：钙钛矿，ABX₃ 结构的材料
- **ALIGNN**：Atomistic Line Graph Neural Network，原子线图神经网络

### B. 常见问题 FAQ

**Q1: 需要多少 GPU 内存？**
- 小型模型推理：4-6 GB
- 大型模型推理：16-24 GB
- 训练小型模型：32-40 GB
- 训练大型模型：80+ GB

**Q2: 生成速度有多快？**
- GPU（A100）：每秒 10-20 个结构
- GPU（RTX 3090）：每秒 5-10 个结构
- CPU：每秒 < 1 个结构（不推荐）

**Q3: 可以生成非周期结构吗？**
- 不行，CrystaLLM 专注于周期性晶体结构

**Q4: 支持哪些文件格式？**
- 输入/输出：CIF
- 可转换：POSCAR（VASP）、XYZ、JSON 等（通过 pymatgen）

**Q5: 如何提高生成质量？**
- 降低 temperature（0.6-0.7）
- 减小 top_k（5-10）
- 使用 MCTS + 评分器
- 领域特定模型（如 crystallm_perov_5_small）

**Q6: 可以商业使用吗？**
- 代码：MIT License（自由使用）
- 数据和模型：CC-BY 4.0（需署名）

### C. 错误处理

**错误 1**：`CUDA out of memory`
```bash
# 解决方案 1：使用 CPU
device=cpu

# 解决方案 2：减小 batch size（训练时）
batch_size=16

# 解决方案 3：使用更小的模型
crystallm_v1_small
```

**错误 2**：`Invalid CIF format`
```bash
# 检查 CIF 完整性
python << EOF
from crystallm import CIFTokenizer
tokenizer = CIFTokenizer()
tokens = tokenizer.tokenize_cif(cif_string)
print(f"Token count: {len(tokens)}")
EOF

# 后处理修复
python bin/postprocess.py raw/ processed/
```

**错误 3**：`Model file not found`
```bash
# 确保模型目录包含 ckpt.pt
ls crystallm_v1_small/
# 应看到：ckpt.pt

# 如果缺失，重新下载
python bin/download.py crystallm_v1_small.tar.gz
tar xvf crystallm_v1_small.tar.gz
```

---

**文档版本**：1.0  
**最后更新**：2024-10-17  
**作者**：CrystaLLM 项目团队 + AI Assistant

本文档旨在提供 CrystaLLM 项目的全面分析和使用指南。如有问题或建议，欢迎在 [GitHub Issues](https://github.com/lantunes/CrystaLLM/issues) 提出。
